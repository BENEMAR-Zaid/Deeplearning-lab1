{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4efbe8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "fname =\"D:\\\\Work\\\\Master\\\\S3\\\\Deep Learning\\\\Lab 1\\\\archive\\\\creditcard.csv\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "c460d54c",
   "metadata": {},
   "source": [
    "First we need to vectorise the dataset and split features and target values( predicted values )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5683dd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEADER: \"Time\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\",\"V16\",\"V17\",\"V18\",\"V19\",\"V20\",\"V21\",\"V22\",\"V23\",\"V24\",\"V25\",\"V26\",\"V27\",\"V28\",\"Amount\",\"Class\"\n",
      "EXAMPLE FEATURES: [0.0, -1.3598071336738, -0.0727811733098497, 2.53634673796914, 1.37815522427443, -0.338320769942518, 0.462387777762292, 0.239598554061257, 0.0986979012610507, 0.363786969611213, 0.0907941719789316, -0.551599533260813, -0.617800855762348, -0.991389847235408, -0.311169353699879, 1.46817697209427, -0.470400525259478, 0.207971241929242, 0.0257905801985591, 0.403992960255733, 0.251412098239705, -0.018306777944153, 0.277837575558899, -0.110473910188767, 0.0669280749146731, 0.128539358273528, -0.189114843888824, 0.133558376740387, -0.0210530534538215, 149.62]\n",
      "features.shape: (284807, 30)\n",
      "targets.shape: (284807, 1)\n"
     ]
    }
   ],
   "source": [
    "all_features = []\n",
    "all_targets = []\n",
    "with open(fname) as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i == 0:\n",
    "            print(\"HEADER:\", line.strip())\n",
    "            continue  # Skip header\n",
    "        fields = line.strip().split(\",\")\n",
    "        all_features.append([float(v.replace('\"', \"\")) for v in fields[:-1]])\n",
    "        all_targets.append([int(fields[-1].replace('\"', \"\"))])\n",
    "        if i == 1:\n",
    "            print(\"EXAMPLE FEATURES:\", all_features[-1])\n",
    "\n",
    "features = np.array(all_features, dtype=\"float32\")\n",
    "targets = np.array(all_targets, dtype=\"uint8\")\n",
    "print(\"features.shape:\", features.shape)\n",
    "print(\"targets.shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ab00e4ff",
   "metadata": {},
   "source": [
    "We need to split the data set into training set and testing set ( validation set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c419a17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 227846\n",
      "Number of validation samples: 56961\n"
     ]
    }
   ],
   "source": [
    "num_val_samples = int(len(features) * 0.2)\n",
    "train_features = features[:-num_val_samples]\n",
    "train_targets = targets[:-num_val_samples]\n",
    "val_features = features[-num_val_samples:]\n",
    "val_targets = targets[-num_val_samples:]\n",
    "\n",
    "print(\"Number of training samples:\", len(train_features))\n",
    "print(\"Number of validation samples:\", len(val_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "446384d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive samples in training data: 417 (0.18% of total)\n"
     ]
    }
   ],
   "source": [
    "# Then we will analyze class imbalance in the targets\n",
    "counts = np.bincount(train_targets[:, 0])\n",
    "print(\n",
    "    \"Number of positive samples in training data: {} ({:.2f}% of total)\".format(\n",
    "        counts[1], 100 * float(counts[1]) / len(train_targets)\n",
    "    )\n",
    ")\n",
    "\n",
    "weight_for_0 = 1.0 / counts[0]\n",
    "weight_for_1 = 1.0 / counts[1]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f9752712",
   "metadata": {},
   "source": [
    "Our data set contains numerical features that need to be normalized, that exactlly what we will try to do in the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6c59f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(train_features, axis=0)\n",
    "train_features -= mean\n",
    "val_features -= mean\n",
    "std = np.std(train_features, axis=0)\n",
    "train_features /= std\n",
    "val_features /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e6b9512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               7936      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139,777\n",
      "Trainable params: 139,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We will import Keras from tensorflow to build our classification model and configure the hyperparametres\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(\n",
    "            256, activation=\"relu\", input_shape=(train_features.shape[-1],)\n",
    "        ),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "217fb822",
   "metadata": {},
   "source": [
    "The last step is to train the model with class_weight argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba56bd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "112/112 - 6s - loss: 2.3419e-06 - fn: 49.0000 - fp: 30070.0000 - tn: 197359.0000 - tp: 368.0000 - precision: 0.0121 - recall: 0.8825 - val_loss: 0.0615 - val_fn: 10.0000 - val_fp: 569.0000 - val_tn: 56317.0000 - val_tp: 65.0000 - val_precision: 0.1025 - val_recall: 0.8667 - 6s/epoch - 51ms/step\n",
      "Epoch 2/30\n",
      "112/112 - 3s - loss: 1.5489e-06 - fn: 34.0000 - fp: 7027.0000 - tn: 220402.0000 - tp: 383.0000 - precision: 0.0517 - recall: 0.9185 - val_loss: 0.1365 - val_fn: 6.0000 - val_fp: 2550.0000 - val_tn: 54336.0000 - val_tp: 69.0000 - val_precision: 0.0263 - val_recall: 0.9200 - 3s/epoch - 30ms/step\n",
      "Epoch 3/30\n",
      "112/112 - 4s - loss: 1.1905e-06 - fn: 28.0000 - fp: 6737.0000 - tn: 220692.0000 - tp: 389.0000 - precision: 0.0546 - recall: 0.9329 - val_loss: 0.0964 - val_fn: 6.0000 - val_fp: 2194.0000 - val_tn: 54692.0000 - val_tp: 69.0000 - val_precision: 0.0305 - val_recall: 0.9200 - 4s/epoch - 37ms/step\n",
      "Epoch 4/30\n",
      "112/112 - 6s - loss: 1.1042e-06 - fn: 22.0000 - fp: 8845.0000 - tn: 218584.0000 - tp: 395.0000 - precision: 0.0427 - recall: 0.9472 - val_loss: 0.1121 - val_fn: 6.0000 - val_fp: 1732.0000 - val_tn: 55154.0000 - val_tp: 69.0000 - val_precision: 0.0383 - val_recall: 0.9200 - 6s/epoch - 49ms/step\n",
      "Epoch 5/30\n",
      "112/112 - 5s - loss: 9.8560e-07 - fn: 23.0000 - fp: 7392.0000 - tn: 220037.0000 - tp: 394.0000 - precision: 0.0506 - recall: 0.9448 - val_loss: 0.0970 - val_fn: 6.0000 - val_fp: 1866.0000 - val_tn: 55020.0000 - val_tp: 69.0000 - val_precision: 0.0357 - val_recall: 0.9200 - 5s/epoch - 48ms/step\n",
      "Epoch 6/30\n",
      "112/112 - 5s - loss: 7.7051e-07 - fn: 16.0000 - fp: 5735.0000 - tn: 221694.0000 - tp: 401.0000 - precision: 0.0654 - recall: 0.9616 - val_loss: 0.0544 - val_fn: 7.0000 - val_fp: 920.0000 - val_tn: 55966.0000 - val_tp: 68.0000 - val_precision: 0.0688 - val_recall: 0.9067 - 5s/epoch - 47ms/step\n",
      "Epoch 7/30\n",
      "112/112 - 5s - loss: 7.3534e-07 - fn: 14.0000 - fp: 6933.0000 - tn: 220496.0000 - tp: 403.0000 - precision: 0.0549 - recall: 0.9664 - val_loss: 0.0480 - val_fn: 8.0000 - val_fp: 1003.0000 - val_tn: 55883.0000 - val_tp: 67.0000 - val_precision: 0.0626 - val_recall: 0.8933 - 5s/epoch - 43ms/step\n",
      "Epoch 8/30\n",
      "112/112 - 5s - loss: 6.5844e-07 - fn: 16.0000 - fp: 6823.0000 - tn: 220606.0000 - tp: 401.0000 - precision: 0.0555 - recall: 0.9616 - val_loss: 0.0916 - val_fn: 6.0000 - val_fp: 2520.0000 - val_tn: 54366.0000 - val_tp: 69.0000 - val_precision: 0.0267 - val_recall: 0.9200 - 5s/epoch - 44ms/step\n",
      "Epoch 9/30\n",
      "112/112 - 5s - loss: 6.5017e-07 - fn: 11.0000 - fp: 6409.0000 - tn: 221020.0000 - tp: 406.0000 - precision: 0.0596 - recall: 0.9736 - val_loss: 0.0477 - val_fn: 8.0000 - val_fp: 847.0000 - val_tn: 56039.0000 - val_tp: 67.0000 - val_precision: 0.0733 - val_recall: 0.8933 - 5s/epoch - 45ms/step\n",
      "Epoch 10/30\n",
      "112/112 - 4s - loss: 5.3595e-07 - fn: 10.0000 - fp: 5162.0000 - tn: 222267.0000 - tp: 407.0000 - precision: 0.0731 - recall: 0.9760 - val_loss: 0.0268 - val_fn: 10.0000 - val_fp: 560.0000 - val_tn: 56326.0000 - val_tp: 65.0000 - val_precision: 0.1040 - val_recall: 0.8667 - 4s/epoch - 33ms/step\n",
      "Epoch 11/30\n",
      "112/112 - 5s - loss: 1.5486e-06 - fn: 21.0000 - fp: 9320.0000 - tn: 218109.0000 - tp: 396.0000 - precision: 0.0408 - recall: 0.9496 - val_loss: 0.0792 - val_fn: 8.0000 - val_fp: 1053.0000 - val_tn: 55833.0000 - val_tp: 67.0000 - val_precision: 0.0598 - val_recall: 0.8933 - 5s/epoch - 41ms/step\n",
      "Epoch 12/30\n",
      "112/112 - 4s - loss: 1.3660e-06 - fn: 26.0000 - fp: 7325.0000 - tn: 220104.0000 - tp: 391.0000 - precision: 0.0507 - recall: 0.9376 - val_loss: 0.1128 - val_fn: 7.0000 - val_fp: 2391.0000 - val_tn: 54495.0000 - val_tp: 68.0000 - val_precision: 0.0277 - val_recall: 0.9067 - 4s/epoch - 38ms/step\n",
      "Epoch 13/30\n",
      "112/112 - 4s - loss: 9.5741e-07 - fn: 20.0000 - fp: 7183.0000 - tn: 220246.0000 - tp: 397.0000 - precision: 0.0524 - recall: 0.9520 - val_loss: 0.0949 - val_fn: 7.0000 - val_fp: 2031.0000 - val_tn: 54855.0000 - val_tp: 68.0000 - val_precision: 0.0324 - val_recall: 0.9067 - 4s/epoch - 36ms/step\n",
      "Epoch 14/30\n",
      "112/112 - 4s - loss: 7.5067e-07 - fn: 12.0000 - fp: 6564.0000 - tn: 220865.0000 - tp: 405.0000 - precision: 0.0581 - recall: 0.9712 - val_loss: 0.0499 - val_fn: 8.0000 - val_fp: 1073.0000 - val_tn: 55813.0000 - val_tp: 67.0000 - val_precision: 0.0588 - val_recall: 0.8933 - 4s/epoch - 39ms/step\n",
      "Epoch 15/30\n",
      "112/112 - 4s - loss: 6.9002e-07 - fn: 11.0000 - fp: 6808.0000 - tn: 220621.0000 - tp: 406.0000 - precision: 0.0563 - recall: 0.9736 - val_loss: 0.0460 - val_fn: 9.0000 - val_fp: 827.0000 - val_tn: 56059.0000 - val_tp: 66.0000 - val_precision: 0.0739 - val_recall: 0.8800 - 4s/epoch - 39ms/step\n",
      "Epoch 16/30\n",
      "112/112 - 4s - loss: 9.9767e-07 - fn: 14.0000 - fp: 6158.0000 - tn: 221271.0000 - tp: 403.0000 - precision: 0.0614 - recall: 0.9664 - val_loss: 0.0328 - val_fn: 9.0000 - val_fp: 456.0000 - val_tn: 56430.0000 - val_tp: 66.0000 - val_precision: 0.1264 - val_recall: 0.8800 - 4s/epoch - 34ms/step\n",
      "Epoch 17/30\n",
      "112/112 - 4s - loss: 1.4149e-06 - fn: 11.0000 - fp: 5600.0000 - tn: 221829.0000 - tp: 406.0000 - precision: 0.0676 - recall: 0.9736 - val_loss: 0.0674 - val_fn: 9.0000 - val_fp: 1238.0000 - val_tn: 55648.0000 - val_tp: 66.0000 - val_precision: 0.0506 - val_recall: 0.8800 - 4s/epoch - 38ms/step\n",
      "Epoch 18/30\n",
      "112/112 - 4s - loss: 5.7783e-07 - fn: 10.0000 - fp: 5955.0000 - tn: 221474.0000 - tp: 407.0000 - precision: 0.0640 - recall: 0.9760 - val_loss: 0.0298 - val_fn: 9.0000 - val_fp: 613.0000 - val_tn: 56273.0000 - val_tp: 66.0000 - val_precision: 0.0972 - val_recall: 0.8800 - 4s/epoch - 38ms/step\n",
      "Epoch 19/30\n",
      "112/112 - 4s - loss: 3.9555e-07 - fn: 5.0000 - fp: 4217.0000 - tn: 223212.0000 - tp: 412.0000 - precision: 0.0890 - recall: 0.9880 - val_loss: 0.0658 - val_fn: 6.0000 - val_fp: 1004.0000 - val_tn: 55882.0000 - val_tp: 69.0000 - val_precision: 0.0643 - val_recall: 0.9200 - 4s/epoch - 37ms/step\n",
      "Epoch 20/30\n",
      "112/112 - 4s - loss: 4.6356e-07 - fn: 7.0000 - fp: 4975.0000 - tn: 222454.0000 - tp: 410.0000 - precision: 0.0761 - recall: 0.9832 - val_loss: 0.0191 - val_fn: 8.0000 - val_fp: 429.0000 - val_tn: 56457.0000 - val_tp: 67.0000 - val_precision: 0.1351 - val_recall: 0.8933 - 4s/epoch - 38ms/step\n",
      "Epoch 21/30\n",
      "112/112 - 4s - loss: 4.9565e-07 - fn: 9.0000 - fp: 5330.0000 - tn: 222099.0000 - tp: 408.0000 - precision: 0.0711 - recall: 0.9784 - val_loss: 0.0461 - val_fn: 9.0000 - val_fp: 994.0000 - val_tn: 55892.0000 - val_tp: 66.0000 - val_precision: 0.0623 - val_recall: 0.8800 - 4s/epoch - 37ms/step\n",
      "Epoch 22/30\n",
      "112/112 - 4s - loss: 4.5981e-07 - fn: 3.0000 - fp: 5138.0000 - tn: 222291.0000 - tp: 414.0000 - precision: 0.0746 - recall: 0.9928 - val_loss: 0.0593 - val_fn: 8.0000 - val_fp: 1433.0000 - val_tn: 55453.0000 - val_tp: 67.0000 - val_precision: 0.0447 - val_recall: 0.8933 - 4s/epoch - 36ms/step\n",
      "Epoch 23/30\n",
      "112/112 - 4s - loss: 3.5863e-07 - fn: 4.0000 - fp: 3790.0000 - tn: 223639.0000 - tp: 413.0000 - precision: 0.0983 - recall: 0.9904 - val_loss: 0.0210 - val_fn: 7.0000 - val_fp: 303.0000 - val_tn: 56583.0000 - val_tp: 68.0000 - val_precision: 0.1833 - val_recall: 0.9067 - 4s/epoch - 38ms/step\n",
      "Epoch 24/30\n",
      "112/112 - 4s - loss: 4.7564e-07 - fn: 6.0000 - fp: 4181.0000 - tn: 223248.0000 - tp: 411.0000 - precision: 0.0895 - recall: 0.9856 - val_loss: 0.0748 - val_fn: 5.0000 - val_fp: 1944.0000 - val_tn: 54942.0000 - val_tp: 70.0000 - val_precision: 0.0348 - val_recall: 0.9333 - 4s/epoch - 37ms/step\n",
      "Epoch 25/30\n",
      "112/112 - 4s - loss: 3.5951e-07 - fn: 5.0000 - fp: 4118.0000 - tn: 223311.0000 - tp: 412.0000 - precision: 0.0909 - recall: 0.9880 - val_loss: 0.0267 - val_fn: 8.0000 - val_fp: 524.0000 - val_tn: 56362.0000 - val_tp: 67.0000 - val_precision: 0.1134 - val_recall: 0.8933 - 4s/epoch - 36ms/step\n",
      "Epoch 26/30\n",
      "112/112 - 4s - loss: 1.9646e-07 - fn: 2.0000 - fp: 2270.0000 - tn: 225159.0000 - tp: 415.0000 - precision: 0.1546 - recall: 0.9952 - val_loss: 0.0091 - val_fn: 9.0000 - val_fp: 159.0000 - val_tn: 56727.0000 - val_tp: 66.0000 - val_precision: 0.2933 - val_recall: 0.8800 - 4s/epoch - 36ms/step\n",
      "Epoch 27/30\n",
      "112/112 - 4s - loss: 2.9253e-07 - fn: 2.0000 - fp: 3315.0000 - tn: 224114.0000 - tp: 415.0000 - precision: 0.1113 - recall: 0.9952 - val_loss: 0.0111 - val_fn: 10.0000 - val_fp: 272.0000 - val_tn: 56614.0000 - val_tp: 65.0000 - val_precision: 0.1929 - val_recall: 0.8667 - 4s/epoch - 38ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30\n",
      "112/112 - 4s - loss: 1.9292e-07 - fn: 1.0000 - fp: 2473.0000 - tn: 224956.0000 - tp: 416.0000 - precision: 0.1440 - recall: 0.9976 - val_loss: 0.0153 - val_fn: 11.0000 - val_fp: 299.0000 - val_tn: 56587.0000 - val_tp: 64.0000 - val_precision: 0.1763 - val_recall: 0.8533 - 4s/epoch - 34ms/step\n",
      "Epoch 29/30\n",
      "112/112 - 4s - loss: 2.8427e-07 - fn: 2.0000 - fp: 2856.0000 - tn: 224573.0000 - tp: 415.0000 - precision: 0.1269 - recall: 0.9952 - val_loss: 0.0103 - val_fn: 12.0000 - val_fp: 202.0000 - val_tn: 56684.0000 - val_tp: 63.0000 - val_precision: 0.2377 - val_recall: 0.8400 - 4s/epoch - 36ms/step\n",
      "Epoch 30/30\n",
      "112/112 - 4s - loss: 2.4975e-07 - fn: 3.0000 - fp: 2783.0000 - tn: 224646.0000 - tp: 414.0000 - precision: 0.1295 - recall: 0.9928 - val_loss: 0.0101 - val_fn: 12.0000 - val_fp: 181.0000 - val_tn: 56705.0000 - val_tp: 63.0000 - val_precision: 0.2582 - val_recall: 0.8400 - 4s/epoch - 35ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x214b08e76a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = [\n",
    "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "    keras.metrics.FalsePositives(name=\"fp\"),\n",
    "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "    keras.metrics.TruePositives(name=\"tp\"),\n",
    "    keras.metrics.Precision(name=\"precision\"),\n",
    "    keras.metrics.Recall(name=\"recall\"),\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-2), loss=\"binary_crossentropy\", metrics=metrics\n",
    ")\n",
    "\n",
    "callbacks = [keras.callbacks.ModelCheckpoint(\"fraud_model_at_epoch_{epoch}.h5\")]\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "model.fit(\n",
    "    train_features,\n",
    "    train_targets,\n",
    "    batch_size=2048,\n",
    "    epochs=30,\n",
    "    verbose=2,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(val_features, val_targets),\n",
    "    class_weight=class_weight,\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b84e1fd5",
   "metadata": {},
   "source": [
    "This example looks at the Kaggle Credit Card Fraud Detection dataset to demonstrate how to train a classification model on data with highly imbalanced classes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cbad92d5",
   "metadata": {},
   "source": [
    "In this example we have done how to Imbalanced Classification with a dataset that we have imported as a CSV from Kaggle file and includes numerical and categorical features. we have also handle the numerical features and normalize them.\n",
    "By doing so our dataset is ready to get implemented to our classification model and the last step was training and testing the model which give us a very satisfied results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699a9a48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
